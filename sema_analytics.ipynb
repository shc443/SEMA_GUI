{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_PUpMQ7ltuce",
    "outputId": "9cc813e0-cec6-490b-9656-6677abeeae0b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ihbmDY7ft3Ma",
    "outputId": "0569b251-0405-4723-fced-366ab3a60ab4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cYAcd3Ojo3hT",
    "outputId": "212f2af5-0051-4ff2-aab0-929142f09dfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                 .DS_\n",
      "1    PEI솔루션_VOC응답(2018_2020년)_20210713_s...\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tf/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MultiLabelBinarizer from version 0.22.2.post1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading : PEI솔루션_VOC응답(2018_2020년)_20210713_sample500\n",
      "Setting : PEI솔루션_VOC응답(2018_2020년)_20210713_sample500\n",
      "Inferencing : PEI솔루션_VOC응답(2018_2020년)_20210713_sample500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tf/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, predict dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4748c8752ac748e3926995d7fe381a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Predicting', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering ETC data : PEI솔루션_VOC응답(2018_2020년)_20210713_sample500\n",
      "Extracting Keywords : PEI솔루션_VOC응답(2018_2020년)_20210713_sample500\n",
      "Saving output File : PEI솔루션_VOC응답(2018_2020년)_20210713_sample500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tf/lib/python3.8/site-packages/numpy/core/shape_base.py:121: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  ary = asanyarray(ary)\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers \n",
    "# !pip install pytorch-lightning==1.3.8\n",
    "# !pip install lightning-bolts\n",
    "# !pip install -v python-mecab-ko\n",
    "\n",
    "from pl_bolts.callbacks import PrintTableMetricsCallback\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics.functional import accuracy, f1, auroc\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "# from pytorch_lightning.accelerators import CPUAccelerator\n",
    "# from pytorch_lightning.plugins import NativeMixedPrecisionPlugin, DDPPlugin\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os \n",
    "\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AdamW, BertConfig\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoConfig\n",
    "from transformers import RobertaConfig, RobertaModel\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import pickle \n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# from konlpy.tag import Mecab\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "# import mecab\n",
    "# mecab = mecab.MeCab()\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "class VOC_Dataset2(Dataset):\n",
    "\n",
    "  def __init__(self, data, tokenizer, max_token_len=512):\n",
    "    self.tokenizer = tokenizer\n",
    "    self.data = data\n",
    "    self.max_token_len = max_token_len\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    data_row = self.data.iloc[index]\n",
    "\n",
    "    voc_text   = data_row.VOC\n",
    "    voc_labels = data_row.label\n",
    "\n",
    "    encoding = self.tokenizer.encode_plus(voc_text,\n",
    "                                          add_special_tokens=True,\n",
    "                                          max_length=self.max_token_len,\n",
    "                                          return_token_type_ids=False,\n",
    "                                          padding=\"max_length\",\n",
    "                                          truncation=True,\n",
    "                                          return_attention_mask=True,\n",
    "                                          return_tensors='pt')\n",
    "\n",
    "    return dict(voc_text=voc_text,\n",
    "                input_ids=encoding[\"input_ids\"].flatten(),\n",
    "                attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "                labels=torch.FloatTensor(voc_labels))\n",
    "\n",
    "class VOC_DataModule(pl.LightningDataModule):\n",
    "  def __init__(self, train_df, test_df, tokenizer, batch_size=4, max_token_len=200):\n",
    "    super().__init__()\n",
    "    self.batch_size = batch_size\n",
    "    self.train_df = train_df\n",
    "    self.test_df = test_df\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_token_len = max_token_len\n",
    "    self.test_dataset  = VOC_Dataset2(self.test_df, self.tokenizer, self.max_token_len)\n",
    "\n",
    "  def setup(self, stage=None):\n",
    "    self.train_dataset = VOC_Dataset2(self.train_df, self.tokenizer, self.max_token_len)         \n",
    "    self.test_dataset  = VOC_Dataset2(self.test_df, self.tokenizer, self.max_token_len)\n",
    "    \n",
    "  def train_dataloader(self):\n",
    "    return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "    \n",
    "  def val_dataloader(self):\n",
    "    return DataLoader(self.test_dataset, batch_size=self.batch_size)\n",
    "    \n",
    "  def test_dataloader(self):\n",
    "    return DataLoader(self.test_dataset, batch_size=self.batch_size)\n",
    "  \n",
    "  def predict_dataloader(self):\n",
    "    return DataLoader(self.test_dataset, batch_size=self.batch_size)\n",
    "\n",
    "class VOC_TopicLabeler(pl.LightningModule):\n",
    "  def __init__(self, n_classes, n_training_steps=None, n_warmup_steps=None):\n",
    "    super().__init__()\n",
    "    self.config = config\n",
    "    # self.config = AutoConfig.from_pretrained(\"klue/roberta-base\", output_hidden_states=True)\n",
    "    # self.config.max_position_embeddings = 512\n",
    "    self.model = AutoModelForMaskedLM.from_pretrained(\"klue/roberta-base\", config=self.config)\n",
    "    self.classifier = nn.Linear(self.model.config.hidden_size, n_classes)\n",
    "    self.n_training_steps = n_training_steps\n",
    "    self.n_warmup_steps = n_warmup_steps\n",
    "    self.criterion = nn.BCEWithLogitsLoss() #nn.BCELoss() with sigmoid layer \n",
    "    self.dropout = nn.Dropout(self.config.hidden_dropout_prob) \n",
    "    self.dense = nn.Linear(self.model.config.hidden_size, self.model.config.hidden_size)\n",
    "    self.activation = nn.Tanh()\n",
    "\n",
    "  def forward(self, input_ids, attention_mask, labels=None):\n",
    "    output = self.model(input_ids, attention_mask=attention_mask)\n",
    "    last_hidden_state = output.hidden_states[-1]\n",
    "    pooled_output = self.classifier(self.dropout(self.activation(self.dense(last_hidden_state[:,0]))))\n",
    "    loss = 0\n",
    "    if labels is not None:\n",
    "        loss = self.criterion(pooled_output, labels)\n",
    "    return loss, torch.sigmoid(pooled_output)\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs = self(input_ids, attention_mask, labels)\n",
    "    self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "    return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs = self(input_ids, attention_mask, labels)\n",
    "    self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "    return loss\n",
    "\n",
    "  def test_step(self, batch, batch_idx):\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs = self(input_ids, attention_mask, labels)\n",
    "    self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "    return loss\n",
    "\n",
    "  def predict_step(self, batch, batch_idx, dataset_idx):\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs = self(input_ids, attention_mask, labels)\n",
    "    self.log(\"predic_loss\", loss, prog_bar=True, logger=True)\n",
    "    return loss, outputs\n",
    "\n",
    "  def training_epoch_end(self, outputs):\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    for output in outputs:\n",
    "      for out_labels in output[\"labels\"].detach().cpu():\n",
    "        labels.append(out_labels)\n",
    "      for out_predictions in output[\"predictions\"].detach().cpu():\n",
    "        predictions.append(out_predictions)\n",
    "    labels = torch.stack(labels).int()\n",
    "    predictions = torch.stack(predictions)\n",
    "    for i, name in enumerate(LABEL_COLUMNS):\n",
    "      class_roc_auc = auroc(predictions[:, i], labels[:, i])\n",
    "      self.logger.experiment.add_scalar(f\"{name}_roc_auc/Train\", class_roc_auc, self.current_epoch)\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    optimizer = AdamW(self.parameters(), lr=2e-5)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=self.n_warmup_steps, num_training_steps=self.n_training_steps)\n",
    "    return dict(optimizer=optimizer, lr_scheduler=dict(scheduler=scheduler, interval='step'))\n",
    "\n",
    "def findall_vec(key,voc):\n",
    "  try:\n",
    "    return re.findall(key, voc)[0]\n",
    "  except:\n",
    "    return ''\n",
    "\n",
    "def findall_vec2(df):\n",
    "  return findall_vec(df['keyword'],df['VOC'])\n",
    "\n",
    "def filter_etc(df):\n",
    "  voc_col = df['VOC'].apply(lambda x: re.sub('[^A-Za-z0-9가-힣 ]', '', x))\n",
    "  filt0 = (voc_col.str.len() < 2).astype(int)\n",
    "  filt1 = voc_col.apply(lambda x : bool(re.match(r'^[_\\W]+$', str(x).replace(' ','')))).astype(int)\n",
    "  filt2 = voc_col.apply(lambda x : bool(re.match(r'[\\d/-]+$', str(x).replace(' ','')))).astype(int)\n",
    "  filt3 = voc_col.str.replace(' ','').str.split('').fillna('').apply(set).str.len() == 2\n",
    "  filt4 = voc_col.progress_apply(lambda x : tuple(Counter(mecab.morphs(x)).keys())).isin(voc_etc.apply(lambda x : tuple(x.keys())))\n",
    "  return filt0+filt1+filt2+filt3+filt4\n",
    "\n",
    "def filter_etc2(df):\n",
    "  voc_col = df['VOC'].apply(lambda x: re.sub('[^A-Za-z0-9가-힣 ]', '', x))\n",
    "  filt0 = (voc_col.str.len() < 2).astype(int)\n",
    "  filt1 = voc_col.apply(lambda x : bool(re.match(r'^[_\\W]+$', str(x).replace(' ','')))).astype(int)\n",
    "  filt2 = voc_col.apply(lambda x : bool(re.match(r'[\\d/-]+$', str(x).replace(' ','')))).astype(int)\n",
    "  filt3 = voc_col.str.replace(' ','').str.split('').fillna('').apply(set).str.len() == 2\n",
    "#   filt4 = voc_col.progress_apply(lambda x : tuple(Counter(mecab.morphs(x)).keys())).isin(voc_etc2.apply(lambda x : tuple(x.keys())))\n",
    "  voc_col_enc = voc_col.apply(lambda x : Counter(tokenizer.encode_plus(x,\n",
    "                      add_special_tokens=True,\n",
    "                      max_length=200,\n",
    "                      return_token_type_ids=False,\n",
    "                      truncation=True,\n",
    "                      return_attention_mask=True,\n",
    "                      return_tensors='pt')['input_ids'].numpy()[0][1:-1]).keys())\n",
    "  filt4 = voc_col_enc.apply(lambda x : ','.join([str(y) for y in x])).isin(voc_etc2.apply(lambda x : ','.join([str(y) for y in x.keys()])))\n",
    "  return filt0+filt1+filt2+filt3+filt4\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "  \n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-base\")\n",
    "# model = AutoModelForMaskedLM.from_pretrained(\"klue/roberta-base\", return_dict=True)\n",
    "#parameters\n",
    "N_EPOCHS = 10\n",
    "BATCH_SIZE = 12\n",
    "MAX_LEN = 256\n",
    "LR = 2e-05\n",
    "opt_thresh = 0.4\n",
    "\n",
    "\n",
    "# config_path=os.path.abspath(os.getcwd())+'/config.json'\n",
    "# directory = '/content/drive/MyDrive/sema/'\n",
    "directory = os.path.abspath(os.getcwd())\n",
    "\n",
    "input_files = pd.Series([f[:-5] for f in listdir(directory+'/voc_data') if isfile(join(directory+'/voc_data', f))])\n",
    "output_files = [f[:-5] for f in listdir(directory+'/output') if isfile(join(directory+'/output', f))]\n",
    "running_files = input_files[~(input_files+'_output').isin(output_files)]\n",
    "print(running_files)\n",
    "\n",
    "#Load Model\n",
    "tokenizer = pickle.load(open(directory+\"/tokenizer.pkl\", \"rb\"))\n",
    "config = pickle.load(open(directory+\"/config.pkl\", \"rb\"))\n",
    "# model = pickle.load(open(directory+\"model.pkl\", \"rb\"))\n",
    "with open(directory+'/data.pkl', 'rb') as f:\n",
    "    mlb = pickle.load(f)\n",
    "LABEL_COLUMNS = mlb.classes_[:]\n",
    "voc_etc2 = pd.read_pickle(directory+'/voc_etc2.pkl')\n",
    "# voc_etc = pd.read_pickle(directory+'/voc_etc.pkl')\n",
    "# voc_etc = pd.concat([voc_etc,pd.Series([Counter(mecab.morphs('모름'))])])[:]\n",
    "# voc_etc = voc_etc.apply(lambda x : np.array(sorted(x.keys())))\n",
    "# keyword = pd.read_pickle('/content/drive/MyDrive/sema/keyword.pkl')\n",
    "keyword = pd.read_pickle(directory+'/keyword.pkl')\n",
    "\n",
    "\n",
    "new_model = VOC_TopicLabeler.load_from_checkpoint(checkpoint_path=directory+\"/model_weights/hosrevroberta_210825_5.ckpt\", n_classes=len(LABEL_COLUMNS))\n",
    "new_model.eval()\n",
    "\n",
    "for file in running_files[~running_files.str.startswith('.')]:\n",
    "  #input files \n",
    "  print('Reading : ' + file)\n",
    "  voc_testset = pd.read_excel(directory+'/voc_data/' + file +'.xlsx',dtype=str)\n",
    "  voc_testset['VOC1'] = voc_testset.VOC1.str.replace('\\n',' ')\n",
    "  voc_testset['VOC2'] = voc_testset.VOC2.str.replace('\\n',' ')\n",
    "\n",
    "  voc = pd.concat([voc_testset.VOC1,voc_testset.VOC2]).sort_index().values\n",
    "  voc_testset = pd.concat([voc_testset]*2).sort_index().iloc[:,:-2]\n",
    "  voc_testset['VOC'] = voc\n",
    "  voc_testset['VOC'].fillna('',inplace=True)\n",
    "  voc_testset['VOC'] = voc_testset['VOC'].apply(str)\n",
    "  voc_testset.reset_index(inplace=True)\n",
    "  voc_testset['label'] = pd.DataFrame(np.zeros((len(mlb.classes_),voc_testset.shape[0])).T).astype(int).apply(list, axis=1)\n",
    "\n",
    "  #Setup\n",
    "  print('Setting : ' + file)\n",
    "  data_module = VOC_DataModule(voc_testset, voc_testset, tokenizer, batch_size=BATCH_SIZE, max_token_len=MAX_LEN)\n",
    "  data_module.setup()\n",
    "#   accelerator = CPUAccelerator(training_type_plugin=DDPPlugin(),precision_plugin=NativeMixedPrecisionPlugin())\n",
    "#   trainer = pl.Trainer(accelerator=accelerator,max_epochs=N_EPOCHS, progress_bar_refresh_rate=3)\n",
    "  trainer = pl.Trainer(max_epochs=N_EPOCHS, progress_bar_refresh_rate=3)\n",
    "\n",
    "  #Inference\n",
    "  print('Inferencing : ' + file)\n",
    "  testing_predict = trainer.predict(new_model, datamodule=data_module)\n",
    "  sema_df_final = np.vstack(pd.Series(np.vstack(testing_predict)[:,1]).apply(lambda x : np.vstack(x.detach().cpu().clone().numpy())))\n",
    "  pred_label = (sema_df_final>opt_thresh).astype(int)\n",
    "  voc_testset['pred'] = pd.Series(mlb.inverse_transform(pred_label)).apply(list)\n",
    "  del voc_testset['label']\n",
    "\n",
    "  #기타\n",
    "  print('Filtering ETC data : ' + file)\n",
    "  \n",
    "  testing = filter_etc2(voc_testset)\n",
    "\n",
    "  voc_testset.pred.loc[testing>0] = [[] for _ in range((testing>0).sum())]\n",
    "  voc_testset = voc_testset.explode('pred',ignore_index=True)\n",
    "\n",
    "  #키워드\n",
    "  print('Extracting Keywords : ' + file)\n",
    "  voc_testset['topic'] = voc_testset.pred.str.split('_').str[0]\n",
    "  voc_testset['sentiment'] = voc_testset.pred.str.split('_').str[1]\n",
    "  voc_testset.topic.fillna('기타',inplace=True)\n",
    "  voc_testset['keyword'] = keyword.loc[voc_testset.topic].values\n",
    "  voc_testset['keyword'] = voc_testset.apply(findall_vec2, axis=1)\n",
    "\n",
    "  #save\n",
    "  print('Saving output File : ' + file)\n",
    "  try:\n",
    "    voc_testset.fillna('').astype(str).to_excel(directory+'/output/' + file +'_output.xlsx',encoding='utf-8-sig',engine='openpyxl')\n",
    "  except: \n",
    "    voc_testset.fillna('').astype(str).to_excel(directory+'/output/' + file +'_output.xlsx',encoding='utf-8-sig',engine='xlsxwriter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading : PEI솔루션_VOC응답(2018_2020년)_20210713_sample500\n",
      "Setting : PEI솔루션_VOC응답(2018_2020년)_20210713_sample500\n",
      "Inferencing : PEI솔루션_VOC응답(2018_2020년)_20210713_sample500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tf/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:102: UserWarning: The dataloader, predict dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298e28de811041f4ad67702de245682f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Predicting', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tf/lib/python3.8/site-packages/numpy/core/shape_base.py:121: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  ary = asanyarray(ary)\n",
      "  0%| | 1/1000 [00:00<00:00, 4739"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering ETC data : PEI솔루션_VOC응답(2018_2020년)_20210713_sample500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mecab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fl/bmf3bcv10m720gkq146ssfkr0000gn/T/ipykernel_12376/1845176363.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Filtering ETC data : '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m   \u001b[0mtesting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_etc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc_testset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0mvoc_testset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/fl/bmf3bcv10m720gkq146ssfkr0000gn/T/ipykernel_12376/3433428920.py\u001b[0m in \u001b[0;36mfilter_etc\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    196\u001b[0m   \u001b[0mfilt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvoc_col\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[\\d/-]+$'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m   \u001b[0mfilt3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvoc_col\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m   \u001b[0mfilt4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvoc_col\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmecab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc_etc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mfilt0\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilt1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilt2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilt3\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilt4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tf/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    768\u001b[0m                 \u001b[0;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tf/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4136\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4138\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tf/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    763\u001b[0m                     \u001b[0;31m# take a fast or slow code path; so stop when t.total==t.n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/fl/bmf3bcv10m720gkq146ssfkr0000gn/T/ipykernel_12376/3433428920.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    196\u001b[0m   \u001b[0mfilt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvoc_col\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[\\d/-]+$'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m   \u001b[0mfilt3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvoc_col\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m   \u001b[0mfilt4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvoc_col\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmecab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc_etc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mfilt0\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilt1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilt2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilt3\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilt4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mecab' is not defined"
     ]
    }
   ],
   "source": [
    "for file in running_files[~running_files.str.startswith('.')]:\n",
    "  #input files \n",
    "  print('Reading : ' + file)\n",
    "  voc_testset = pd.read_excel(directory+'/voc_data/' + file +'.xlsx',dtype=str)\n",
    "  voc_testset['VOC1'] = voc_testset.VOC1.str.replace('\\n',' ')\n",
    "  voc_testset['VOC2'] = voc_testset.VOC2.str.replace('\\n',' ')\n",
    "\n",
    "  voc = pd.concat([voc_testset.VOC1,voc_testset.VOC2]).sort_index().values\n",
    "  voc_testset = pd.concat([voc_testset]*2).sort_index().iloc[:,:-2]\n",
    "  voc_testset['VOC'] = voc\n",
    "  voc_testset['VOC'].fillna('',inplace=True)\n",
    "  voc_testset['VOC'] = voc_testset['VOC'].apply(str)\n",
    "  voc_testset.reset_index(inplace=True)\n",
    "  voc_testset['label'] = pd.DataFrame(np.zeros((len(mlb.classes_),voc_testset.shape[0])).T).astype(int).apply(list, axis=1)\n",
    "\n",
    "  #Setup\n",
    "  print('Setting : ' + file)\n",
    "  data_module = VOC_DataModule(voc_testset, voc_testset, tokenizer, batch_size=BATCH_SIZE, max_token_len=MAX_LEN)\n",
    "  data_module.setup()\n",
    "#   accelerator = CPUAccelerator(training_type_plugin=DDPPlugin(),precision_plugin=NativeMixedPrecisionPlugin())\n",
    "#   trainer = pl.Trainer(accelerator=accelerator,max_epochs=N_EPOCHS, progress_bar_refresh_rate=3)\n",
    "  trainer = pl.Trainer(max_epochs=N_EPOCHS, progress_bar_refresh_rate=3)\n",
    "\n",
    "  #Inference\n",
    "  print('Inferencing : ' + file)\n",
    "  testing_predict = trainer.predict(new_model, datamodule=data_module)\n",
    "  sema_df_final = np.vstack(pd.Series(np.vstack(testing_predict)[:,1]).apply(lambda x : np.vstack(x.detach().cpu().clone().numpy())))\n",
    "  pred_label = (sema_df_final>opt_thresh).astype(int)\n",
    "  voc_testset['pred'] = pd.Series(mlb.inverse_transform(pred_label)).apply(list)\n",
    "  del voc_testset['label']\n",
    "\n",
    "  #기타\n",
    "  print('Filtering ETC data : ' + file)\n",
    "  \n",
    "  testing = filter_etc2(voc_testset)\n",
    "\n",
    "  voc_testset.pred.loc[testing>0] = [[] for _ in range((testing>0).sum())]\n",
    "  voc_testset = voc_testset.explode('pred',ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191,
     "referenced_widgets": [
      "fd162b5765bf41c7837f8dea7846cb73",
      "6059f27036de4fba84548ad8d0482b12",
      "38c946550c444c95b5151b4037d5449f",
      "7364a1245c864bb5be9b1f1b4ca6bb8b",
      "eb4b8b78838045548b4f1f262ed0f9b7",
      "45aa2d26f5164c58ae6007955ac63d4c",
      "0aee33bd46f24ae596e49f6debc3f3b5",
      "070c20b5a46c480c8f0b8c89a9645af0",
      "8ebc823d00b3484e945825b8a39c83e2",
      "b13169eb461f41b6a6fe76f75efa0a51",
      "0a91f087f451472d881cfa960f513198"
     ]
    },
    "id": "6xi5TVj4rjRF",
    "outputId": "a6410ebb-f07c-4a42-e2f4-ddf8348b304d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading : PEI솔루션_VOC응답(2018_2020년)_20210713_sample500_2 (1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting : PEI솔루션_VOC응답(2018_2020년)_20210713_sample500_2 (1)\n",
      "Inferencing : PEI솔루션_VOC응답(2018_2020년)_20210713_sample500_2 (1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:597: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  \"GPU available but not used. Set the gpus flag in your trainer\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd162b5765bf41c7837f8dea7846cb73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for file in running_files:\n",
    "  #input files \n",
    "  print('Reading : ' + file)\n",
    "  voc_testset = pd.read_excel(directory+'/voc_data/' + file +'.xlsx',dtype=str)\n",
    "  voc_testset['VOC1'] = voc_testset.VOC1.str.replace('\\n',' ')\n",
    "  voc_testset['VOC2'] = voc_testset.VOC2.str.replace('\\n',' ')\n",
    "\n",
    "  voc = pd.concat([voc_testset.VOC1,voc_testset.VOC2]).sort_index().values\n",
    "  voc_testset = pd.concat([voc_testset]*2).sort_index().iloc[:,:-2]\n",
    "  voc_testset['VOC'] = voc\n",
    "  voc_testset['VOC'].fillna('',inplace=True)\n",
    "  voc_testset['VOC'] = voc_testset['VOC'].apply(str)\n",
    "  voc_testset.reset_index(inplace=True)\n",
    "  voc_testset['label'] = pd.DataFrame(np.zeros((len(mlb.classes_),voc_testset.shape[0])).T).astype(int).apply(list, axis=1)\n",
    "\n",
    "  #Setup\n",
    "  print('Setting : ' + file)\n",
    "  data_module = VOC_DataModule(voc_testset, voc_testset, tokenizer, batch_size=BATCH_SIZE, max_token_len=MAX_LEN)\n",
    "  data_module.setup()\n",
    "  trainer = pl.Trainer(max_epochs=N_EPOCHS, progress_bar_refresh_rate=3)\n",
    "\n",
    "  #Inference\n",
    "  print('Inferencing : ' + file)\n",
    "  testing_predict = trainer.predict(new_model, datamodule=data_module)\n",
    "  sema_df_final = np.vstack(pd.Series(np.vstack(testing_predict)[:,1]).apply(lambda x : np.vstack(x.detach().cpu().clone().numpy())))\n",
    "  pred_label = (sema_df_final>opt_thresh).astype(int)\n",
    "  voc_testset['pred'] = pd.Series(mlb.inverse_transform(pred_label)).apply(list)\n",
    "  del voc_testset['label']\n",
    "\n",
    "  #기타\n",
    "  print('Filtering ETC data : ' + file)\n",
    "  \n",
    "  testing = filter_etc(voc_testset)\n",
    "\n",
    "  voc_testset.pred.loc[testing>0] = [[] for _ in range((testing>0).sum())]\n",
    "  voc_testset = voc_testset.explode('pred',ignore_index=True)\n",
    "\n",
    "  #키워드\n",
    "  print('Extracting Keywords : ' + file)\n",
    "  voc_testset['topic'] = voc_testset.pred.str.split('_').str[0]\n",
    "  voc_testset['sentiment'] = voc_testset.pred.str.split('_').str[1]\n",
    "  voc_testset.topic.fillna('기타',inplace=True)\n",
    "  voc_testset['keyword'] = keyword.loc[voc_testset.topic].values\n",
    "  voc_testset['keyword'] = voc_testset.apply(findall_vec2, axis=1)\n",
    "\n",
    "  #save\n",
    "  print('Saving output File : ' + file)\n",
    "  voc_testset.fillna('').astype(str).to_excel(directory+'/output/' + file +'_output.xlsx',encoding='utf-8-sig',engine='openpyxl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "05o0WgabpE8Q"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>설문번호</th>\n",
       "      <th>아이디</th>\n",
       "      <th>조사시작시간</th>\n",
       "      <th>조사종료시간</th>\n",
       "      <th>병원코드</th>\n",
       "      <th>진료과 코드</th>\n",
       "      <th>의사코드</th>\n",
       "      <th>병동코드</th>\n",
       "      <th>VOC</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018102201</td>\n",
       "      <td>R508198794131698367</td>\n",
       "      <td>2018-10-22 16:23</td>\n",
       "      <td>2018-10-22 16:25</td>\n",
       "      <td>37524895</td>\n",
       "      <td>4900</td>\n",
       "      <td>3752490000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>해당사항없음</td>\n",
       "      <td>[진료경험(진료/투약/검사/회진)_부정]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2018102201</td>\n",
       "      <td>R8646383274773023108</td>\n",
       "      <td>2018-10-22 19:38</td>\n",
       "      <td>2018-10-22 21:11</td>\n",
       "      <td>37524895</td>\n",
       "      <td>4900</td>\n",
       "      <td>3752490000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>대기시간이짫다,</td>\n",
       "      <td>[대기시간_부정, 주차_부정]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2018102201</td>\n",
       "      <td>R2293067998190858561</td>\n",
       "      <td>2018-10-22 21:28</td>\n",
       "      <td>2018-10-22 21:34</td>\n",
       "      <td>37524895</td>\n",
       "      <td>4900</td>\n",
       "      <td>3752490000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>만족함</td>\n",
       "      <td>[진료경험(진료/투약/검사/회진)_긍정]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2018102201</td>\n",
       "      <td>R2293067998190858561</td>\n",
       "      <td>2018-10-22 21:28</td>\n",
       "      <td>2018-10-22 21:34</td>\n",
       "      <td>37524895</td>\n",
       "      <td>4900</td>\n",
       "      <td>3752490000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>잘모러곘음</td>\n",
       "      <td>[주차_부정]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2018102201</td>\n",
       "      <td>R9693965189165712177</td>\n",
       "      <td>2018-10-23 15:13</td>\n",
       "      <td>2018-10-23 15:16</td>\n",
       "      <td>37524895</td>\n",
       "      <td>4900</td>\n",
       "      <td>3752490000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>없습니다</td>\n",
       "      <td>[병원시스템_부정]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>497</td>\n",
       "      <td>497</td>\n",
       "      <td>2018110501</td>\n",
       "      <td>R1376130336939876174</td>\n",
       "      <td>2018-11-07 18:54</td>\n",
       "      <td>2018-11-07 19:08</td>\n",
       "      <td>37100017</td>\n",
       "      <td>600</td>\n",
       "      <td>3710000000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>없음</td>\n",
       "      <td>[병원시스템_부정]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>2018110501</td>\n",
       "      <td>R2525668391215629643</td>\n",
       "      <td>2018-11-07 18:55</td>\n",
       "      <td>2018-11-07 19:00</td>\n",
       "      <td>37100017</td>\n",
       "      <td>101</td>\n",
       "      <td>3710000000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>..</td>\n",
       "      <td>[주차_부정]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>2018110501</td>\n",
       "      <td>R2525668391215629643</td>\n",
       "      <td>2018-11-07 18:55</td>\n",
       "      <td>2018-11-07 19:00</td>\n",
       "      <td>37100017</td>\n",
       "      <td>101</td>\n",
       "      <td>3710000000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>..</td>\n",
       "      <td>[주차_부정]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>499</td>\n",
       "      <td>499</td>\n",
       "      <td>2018110501</td>\n",
       "      <td>R9377744594635125576</td>\n",
       "      <td>2018-11-07 19:09</td>\n",
       "      <td>2018-11-07 19:12</td>\n",
       "      <td>37100017</td>\n",
       "      <td>500</td>\n",
       "      <td>3710000000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>..</td>\n",
       "      <td>[주차_부정]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>499</td>\n",
       "      <td>499</td>\n",
       "      <td>2018110501</td>\n",
       "      <td>R9377744594635125576</td>\n",
       "      <td>2018-11-07 19:09</td>\n",
       "      <td>2018-11-07 19:12</td>\n",
       "      <td>37100017</td>\n",
       "      <td>500</td>\n",
       "      <td>3710000000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>..</td>\n",
       "      <td>[주차_부정]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index Unnamed: 0        설문번호                   아이디            조사시작시간  \\\n",
       "1        0          0  2018102201   R508198794131698367  2018-10-22 16:23   \n",
       "4        2          2  2018102201  R8646383274773023108  2018-10-22 19:38   \n",
       "6        3          3  2018102201  R2293067998190858561  2018-10-22 21:28   \n",
       "7        3          3  2018102201  R2293067998190858561  2018-10-22 21:28   \n",
       "13       6          6  2018102201  R9693965189165712177  2018-10-23 15:13   \n",
       "..     ...        ...         ...                   ...               ...   \n",
       "994    497        497  2018110501  R1376130336939876174  2018-11-07 18:54   \n",
       "996    498        498  2018110501  R2525668391215629643  2018-11-07 18:55   \n",
       "997    498        498  2018110501  R2525668391215629643  2018-11-07 18:55   \n",
       "998    499        499  2018110501  R9377744594635125576  2018-11-07 19:09   \n",
       "999    499        499  2018110501  R9377744594635125576  2018-11-07 19:09   \n",
       "\n",
       "               조사종료시간      병원코드 진료과 코드              의사코드 병동코드       VOC  \\\n",
       "1    2018-10-22 16:25  37524895   4900  3752490000000000  NaN    해당사항없음   \n",
       "4    2018-10-22 21:11  37524895   4900  3752490000000000  NaN  대기시간이짫다,   \n",
       "6    2018-10-22 21:34  37524895   4900  3752490000000000  NaN       만족함   \n",
       "7    2018-10-22 21:34  37524895   4900  3752490000000000  NaN     잘모러곘음   \n",
       "13   2018-10-23 15:16  37524895   4900  3752490000000000  NaN      없습니다   \n",
       "..                ...       ...    ...               ...  ...       ...   \n",
       "994  2018-11-07 19:08  37100017    600  3710000000000000  NaN        없음   \n",
       "996  2018-11-07 19:00  37100017    101  3710000000000000  NaN        ..   \n",
       "997  2018-11-07 19:00  37100017    101  3710000000000000  NaN        ..   \n",
       "998  2018-11-07 19:12  37100017    500  3710000000000000  NaN        ..   \n",
       "999  2018-11-07 19:12  37100017    500  3710000000000000  NaN        ..   \n",
       "\n",
       "                       pred  \n",
       "1    [진료경험(진료/투약/검사/회진)_부정]  \n",
       "4          [대기시간_부정, 주차_부정]  \n",
       "6    [진료경험(진료/투약/검사/회진)_긍정]  \n",
       "7                   [주차_부정]  \n",
       "13               [병원시스템_부정]  \n",
       "..                      ...  \n",
       "994              [병원시스템_부정]  \n",
       "996                 [주차_부정]  \n",
       "997                 [주차_부정]  \n",
       "998                 [주차_부정]  \n",
       "999                 [주차_부정]  \n",
       "\n",
       "[280 rows x 12 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing = filter_etc2(voc_testset)\n",
    "\n",
    "# voc_testset.pred.loc[testing>0] = [[] for _ in range((testing>0).sum())]\n",
    "# voc_testset = voc_testset.explode('pred',ignore_index=True)\n",
    "# voc_etc2.apply(lambda x : tuple(x.keys()))\n",
    "def filter_etc2(df):\n",
    "  voc_col = df['VOC'].apply(lambda x: re.sub('[^A-Za-z0-9가-힣 ]', '', x))\n",
    "  filt0 = (voc_col.str.len() < 2).astype(int)\n",
    "  filt1 = voc_col.apply(lambda x : bool(re.match(r'^[_\\W]+$', str(x).replace(' ','')))).astype(int)\n",
    "  filt2 = voc_col.apply(lambda x : bool(re.match(r'[\\d/-]+$', str(x).replace(' ','')))).astype(int)\n",
    "  filt3 = voc_col.str.replace(' ','').str.split('').fillna('').apply(set).str.len() == 2\n",
    "#   filt4 = voc_col.progress_apply(lambda x : tuple(Counter(mecab.morphs(x)).keys())).isin(voc_etc2.apply(lambda x : tuple(x.keys())))\n",
    "  voc_col_enc = voc_col.apply(lambda x : Counter(tokenizer.encode_plus(x,\n",
    "                      add_special_tokens=True,\n",
    "                      max_length=200,\n",
    "                      return_token_type_ids=False,\n",
    "                      truncation=True,\n",
    "                      return_attention_mask=True,\n",
    "                      return_tensors='pt')['input_ids'].numpy()[0][1:-1]).keys())\n",
    "  filt4 = voc_col_enc.apply(lambda x : ','.join([str(y) for y in x])).isin(voc_etc2.apply(lambda x : ','.join([str(y) for y in x.keys()])))\n",
    "  return filt0+filt1+filt2+filt3+filt4\n",
    "voc_testset[filter_etc2(voc_testset)>0]\n",
    "# voc_enccc = voc_testset['VOC'].apply(lambda x: re.sub('[^A-Za-z0-9가-힣 ]', '', x)).apply(lambda x : list(Counter(tokenizer.encode_plus(x,\n",
    "#                       add_special_tokens=True,\n",
    "#                       max_length=200,\n",
    "#                       return_token_type_ids=False,\n",
    "#                       truncation=True,\n",
    "#                       return_attention_mask=True,\n",
    "#                       return_tensors='pt')['input_ids'].numpy()[0][1:-1]).keys()))#.isin(voc_etc2.apply(lambda x : tuple(x.keys())))#\n",
    "# voc_enccc.apply(lambda x : ','.join([str(y) for y in x])).isin(voc_etc2.apply(lambda x : ','.join([str(y) for y in x.keys()])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ACjcJVSRtESu"
   },
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-pQeEFAztFhe",
    "outputId": "fd1740ab-aecc-4660-fd95-0b543b82d417"
   },
   "outputs": [],
   "source": [
    "voc_etc2 = pd.read_pickle(directory+'/voc_etc2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "u4uWW-fUtQn7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          괜찬았어요\n",
       "1                               \n",
       "2                        아픈것이해결됨\n",
       "3      모두모두가서로를배려하다면점더좋은진료환경이되겠죠\n",
       "4                 체계적인연계진료에감동받았다\n",
       "                 ...            \n",
       "333                      잘해주시고계심\n",
       "334                         잘하세요\n",
       "335                          없네여\n",
       "336                           모름\n",
       "337                         없더군요\n",
       "Length: 338, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc1_sema = pd.read_excel('~/Downloads/voc1_sema.xlsx')\n",
    "voc2_sema = pd.read_excel('~/Downloads/voc2_sema.xlsx')\n",
    "voc_etc_list = list(set(voc1_sema[voc1_sema.토픽=='기타'].VOC12.tolist())) + list(set(voc2_sema[voc2_sema.토픽=='기타']['VOC2.1'].tolist()))\n",
    "voc_etc_list2 = pd.Series((voc_etc_list+['전혀 없음','업ㅇㄷㅁ','그저 그렇다','그저 그럼','잘 모름', '대체로 만족합니다.', '대체로 만족합니다','별로 없음','잘해주시고계심','잘하세요','없네여','모름','없더군요'])).str.replace(r'\\W','',regex=True)\n",
    "voc_etc_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "voc_etc_list2.apply(lambda x : Counter(tokenizer.encode_plus(x,\n",
    "                      add_special_tokens=True,\n",
    "                      max_length=200,\n",
    "                      return_token_type_ids=False,\n",
    "                      truncation=True,\n",
    "                      return_attention_mask=True,\n",
    "                      return_tensors='pt')['input_ids'].numpy()[0][1:-1])).drop_duplicates().to_pickle('voc_etc2.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading : PEI솔루션_VOC응답(2018_2020년)_20210713_sample500\n",
      "Setting : PEI솔루션_VOC응답(2018_2020년)_20210713_sample500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tf/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:556: UserWarning: You requested distributed training on GPUs, but none is available, so we set backend to `ddp_cpu`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "Selected distributed backend ddp is not compatible with an interactive environment. Run your code as a script, or choose one of the compatible backends: dp, ddp_spawn, ddp_sharded_spawn, tpu_spawn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fl/bmf3bcv10m720gkq146ssfkr0000gn/T/ipykernel_12376/394261791.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mdata_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVOC_DataModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc_testset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoc_testset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_token_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mdata_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar_refresh_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_processes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;31m#Inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tf/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/env_vars_connector.py\u001b[0m in \u001b[0;36minsert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# all args were already moved to kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minsert_env_defaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tf/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, logger, checkpoint_callback, callbacks, default_root_dir, gradient_clip_val, gradient_clip_algorithm, process_position, num_nodes, num_processes, gpus, auto_select_gpus, tpu_cores, log_gpu_memory, progress_bar_refresh_rate, overfit_batches, track_grad_norm, check_val_every_n_epoch, fast_dev_run, accumulate_grad_batches, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, val_check_interval, flush_logs_every_n_steps, log_every_n_steps, accelerator, sync_batchnorm, precision, weights_summary, weights_save_path, num_sanity_val_steps, truncated_bptt_steps, resume_from_checkpoint, profiler, benchmark, deterministic, reload_dataloaders_every_epoch, auto_lr_find, replace_sampler_ddp, terminate_on_nan, auto_scale_batch_size, prepare_data_per_node, plugins, amp_backend, amp_level, distributed_backend, move_metrics_to_cpu, multiple_trainloader_mode, stochastic_weight_avg)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_connector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptimizerConnector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         self.accelerator_connector = AcceleratorConnector(\n\u001b[0m\u001b[1;32m    322\u001b[0m             \u001b[0mnum_processes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpu_cores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_select_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync_batchnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenchmark\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mreplace_sampler_ddp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamp_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamp_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tf/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_processes, tpu_cores, distributed_backend, auto_select_gpus, gpus, num_nodes, sync_batchnorm, benchmark, replace_sampler_ddp, deterministic, precision, amp_type, amp_level, plugins)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_device_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_gpu_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_distributed_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure_slurm_ddp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tf/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py\u001b[0m in \u001b[0;36mset_distributed_mode\u001b[0;34m(self, distributed_backend)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;31m# finished configuring self._distrib_type, check ipython environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_interactive_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# for DDP overwrite nb processes by requested GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tf/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py\u001b[0m in \u001b[0;36mcheck_interactive_compatibility\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_IS_INTERACTIVE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_IS_INTERACTIVE\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distrib_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distrib_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_interactive_compatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             raise MisconfigurationException(\n\u001b[0m\u001b[1;32m    621\u001b[0m                 \u001b[0;34mf\"Selected distributed backend {self._distrib_type} is not compatible with an interactive\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m                 \u001b[0;34m\" environment. Run your code as a script, or choose one of the compatible backends:\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: Selected distributed backend ddp is not compatible with an interactive environment. Run your code as a script, or choose one of the compatible backends: dp, ddp_spawn, ddp_sharded_spawn, tpu_spawn"
     ]
    }
   ],
   "source": [
    "voc_etc2 = pd.read_pickle(directory+'/voc_etc2.pkl')\n",
    "\n",
    "for file in running_files[~running_files.str.startswith('.')]:\n",
    "  #input files \n",
    "  print('Reading : ' + file)\n",
    "  voc_testset = pd.read_excel(directory+'/voc_data/' + file +'.xlsx',dtype=str)\n",
    "  voc_testset['VOC1'] = voc_testset.VOC1.str.replace('\\n',' ')\n",
    "  voc_testset['VOC2'] = voc_testset.VOC2.str.replace('\\n',' ')\n",
    "\n",
    "  voc = pd.concat([voc_testset.VOC1,voc_testset.VOC2]).sort_index().values\n",
    "  voc_testset = pd.concat([voc_testset]*2).sort_index().iloc[:,:-2]\n",
    "  voc_testset['VOC'] = voc\n",
    "  voc_testset['VOC'].fillna('',inplace=True)\n",
    "  voc_testset['VOC'] = voc_testset['VOC'].apply(str)\n",
    "  voc_testset.reset_index(inplace=True)\n",
    "  voc_testset['label'] = pd.DataFrame(np.zeros((len(mlb.classes_),voc_testset.shape[0])).T).astype(int).apply(list, axis=1)\n",
    "\n",
    "  #Setup\n",
    "  print('Setting : ' + file)\n",
    "  data_module = VOC_DataModule(voc_testset, voc_testset, tokenizer, batch_size=BATCH_SIZE, max_token_len=MAX_LEN)\n",
    "  data_module.setup()\n",
    "  trainer = pl.Trainer(max_epochs=N_EPOCHS, progress_bar_refresh_rate=3, )\n",
    "\n",
    "  #Inference\n",
    "  print('Inferencing : ' + file)\n",
    "  testing_predict = trainer.predict(new_model, datamodule=data_module)\n",
    "  sema_df_final = np.vstack(pd.Series(np.vstack(testing_predict)[:,1]).apply(lambda x : np.vstack(x.detach().cpu().clone().numpy())))\n",
    "  pred_label = (sema_df_final>opt_thresh).astype(int)\n",
    "  voc_testset['pred'] = pd.Series(mlb.inverse_transform(pred_label)).apply(list)\n",
    "  del voc_testset['label']\n",
    "\n",
    "  #기타\n",
    "  print('Filtering ETC data : ' + file)\n",
    "  \n",
    "  testing = filter_etc(voc_testset)\n",
    "\n",
    "  voc_testset.pred.loc[testing>0] = [[] for _ in range((testing>0).sum())]\n",
    "  voc_testset = voc_testset.explode('pred',ignore_index=True)\n",
    "\n",
    "  #키워드\n",
    "  print('Extracting Keywords : ' + file)\n",
    "  voc_testset['topic'] = voc_testset.pred.str.split('_').str[0]\n",
    "  voc_testset['sentiment'] = voc_testset.pred.str.split('_').str[1]\n",
    "  voc_testset.topic.fillna('기타',inplace=True)\n",
    "  voc_testset['keyword'] = keyword.loc[voc_testset.topic].values\n",
    "  voc_testset['keyword'] = voc_testset.apply(findall_vec2, axis=1)\n",
    "\n",
    "  #save\n",
    "  print('Saving output File : ' + file)\n",
    "  try:\n",
    "    voc_testset.fillna('').astype(str).to_excel(directory+'/output/' + file +'_output.xlsx',encoding='utf-8-sig',engine='openpyxl')\n",
    "  except: \n",
    "    voc_testset.fillna('').astype(str).to_excel(directory+'/output/' + file +'_output.xlsx',encoding='utf-8-sig',engine='xlsxwriter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.accelerators import CPUAccelerator\n",
    "from pytorch_lightning.plugins import NativeMixedPrecisionPlugin, DDPPlugin\n",
    "\n",
    "accelerator = CPUAccelerator(training_type_plugin=DDPPlugin(),precision_plugin=NativeMixedPrecisionPlugin())\n",
    "trainer = pl.Trainer(accelerator=accelerator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "070c20b5a46c480c8f0b8c89a9645af0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0a91f087f451472d881cfa960f513198": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0aee33bd46f24ae596e49f6debc3f3b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38c946550c444c95b5151b4037d5449f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0aee33bd46f24ae596e49f6debc3f3b5",
      "placeholder": "​",
      "style": "IPY_MODEL_45aa2d26f5164c58ae6007955ac63d4c",
      "value": "Predicting:  32%"
     }
    },
    "45aa2d26f5164c58ae6007955ac63d4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6059f27036de4fba84548ad8d0482b12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "7364a1245c864bb5be9b1f1b4ca6bb8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ebc823d00b3484e945825b8a39c83e2",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_070c20b5a46c480c8f0b8c89a9645af0",
      "value": 1
     }
    },
    "8ebc823d00b3484e945825b8a39c83e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b13169eb461f41b6a6fe76f75efa0a51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eb4b8b78838045548b4f1f262ed0f9b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a91f087f451472d881cfa960f513198",
      "placeholder": "​",
      "style": "IPY_MODEL_b13169eb461f41b6a6fe76f75efa0a51",
      "value": " 27/84 [05:16&lt;11:09, 11.74s/it]"
     }
    },
    "fd162b5765bf41c7837f8dea7846cb73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_38c946550c444c95b5151b4037d5449f",
       "IPY_MODEL_7364a1245c864bb5be9b1f1b4ca6bb8b",
       "IPY_MODEL_eb4b8b78838045548b4f1f262ed0f9b7"
      ],
      "layout": "IPY_MODEL_6059f27036de4fba84548ad8d0482b12"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
